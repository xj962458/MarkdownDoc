### 一、项目介绍
​         该项目是为自动化采集腾讯文档模板页的所有模板而设计的，使用`Python`语言编写，主要使用python的第三方库`selenium`进行设计，运行该项目需要登录相关的账号和密码。运行后会将下载的的文件分类保存，当然，用户也可以选择全部保存在一个文件夹中。项目运行前请先到`Download/path.py`中添加项目所在的绝对路径。

项目目标如下：

  ① 腾讯文档模板数据采集，采集腾讯文档首页上所有模板；

  ② 模板文件下载下来是word格式，统一存储在同一个文件夹中；

  ③ 模板文件的名称需要与模板标题一致。



### 二、项目结构如下

```bash
GetTenDocum
|
├─AllFile
│  └─腾讯文档模板
|  └─腾讯文档模板_测试
|  └─cookies.json
|  └─download_link.json
|
├─Cookie
│  └─__pycache__
|  └─cookie_login.py
|  └─get_cookie.py
└─Download
|  └─__pycache__
|  └─download_file.py
|  └─get_template_link.py
|  └─path.py
├─main.py
├─move.py
├─requirements.txt
└─README.MD
```

1. `AllFile`

   ​        文件夹用于存储项目运行中产生的文件，一是保存的相关配置文件，二是下载的模板；`腾讯文档模板`是用来存储下载后的文档，`腾讯文档模板_测试`是之前测试时下载的所有模板，重新执行项目会删除`腾讯文档模板`里面的所有文档并重新下载。

2. `Cookie`

​         是python的一个包，包含两个与cookie有关的函数，其中`get_cookie.py`用于获取cookie，然后将获取的cookie存储到`AllFile`文件夹下的`cookies.json`文件中，`cookie_login`从文件获取cookie并执行登录操作。

3. `Download`

   ​        也是Python的一个包，包含和下载相关的函数，一个是`get_template_link.py`文件，用于获取所有模板的下载链接，获取后分类存储于`AllFile`文件夹下的`download_link.json`文件中。`download_file.py`包含可以读取`download_link.json`文件获取连接后模拟用户执行下载操作，下载的文件分类保存在`AllFile/腾讯文档模板`文件夹中。还有一个`path.py`，该文件存储了项目的绝对路径，运行项目前请自行添加，用于其他函数的调用，协调该项目既可以整体运行，又可以单模块运行。

4. 函数入口                           
    （1） `main.py`是该项目的入口，控制整个项目的执行，该模块运行时会检测`AllFile`文件夹下是否有`cookies.json`和`download_link.json`文件，若没有检测到，则会调用`get_cookie.py`文件去获取cookie，调用`get_template_link.py`文件去执行下载操作。

​       （2）因cookie有一定的时效，建议运行前删除`cookes.json`文件，并在`Cookie/get_cookie.py`中添加相应的账号密码，重新获取cookie，获取cookie使用的是qq登录，故提供的账号密码为qq账号和密码。若要下载VIP文档，需要添加vip账号，并将主函数中的`vip_down`更改为`True`。

​      （3）程序默认后台执行，不在前台显示，若需要前台显示，请修改主函数中的`background`变量为`False`。          

​                              

5. 其他文件

（1）`requirements.txt`为程序运行所需要的第三方库要求，可以使用`pip install -r requirements.txt`进行自动化安装，本项目在Window11操作系统，AMD4800U处理器，16G内存，python3.9.5下可以完美运行。      


（2）`move.py`是将所有下载的文档移动到一个文件夹中，不同用户有不同的选择，需要移动到同一个文件夹内的用户请运行该文件，运行后会将所有模板文档下载至`./腾讯文档模板/Document中`。默认根据模板类放在不同的文件夹中。 

（3）`README.MD`即本文件，是对项目的的进一步说明。



### 三、项目的主要内容及步骤
#### 1. 设计思路

##### （1）项目分析

该项目的目的是采集腾讯文档主页所有的模板，最初的思路是使用requests库爬取网页，使用BeautifulSoup4解析网页获取下载链接后执行下载操作。后分析腾讯文档模板页的网页代码，得到以下信息：

① 该网页为动态网页，内容随用户的操作而显现的；

② 该网页所有的文档均没有直接的下载链接，都需要进行一系列手动操作，才能实现文档的导出和下载；

③ 文档的下载需要进行登录，未登陆的用户无法进行文档的下载；

④ 文档分为普通文档和VIP文档，非VIP用户不能够下载VIP文档；

⑤ 页面的文档分为多个种类。

##### （2）解决方案

①  使用selenium控制浏览器模拟用户操作并执行文档的下载。

②  设置判定条件，当用户为VIP用户时才进行VIP文档的下载。

③  使用cookie进行用户登录，简化了操作步骤，节省了时间。

④  对文件进行分类下载。以文件所属类名建立文件夹，将下载的文件分别存储在相应的文件夹中，所有以类名命名的文件夹存储在同一文件夹中。

##### （3）具体实现步骤

①  编写获取用户登录cookie的函数，功能是获取cookie，并将获取到的cookie存储到相应的json文件中。

②  编写获取腾讯文档首页所有模板文档访问链接的函数，功能是获取文档访问链接，并将链接分类存储在相应的json文件中。

③  分类读取保存文档下载链接的json文件，根据链接访问文档，读取保存用户cookie的文件并进行登录，并模拟用户来执行文档的下载，并将下载后的文档进行分类存储。

##### (4) 优化

①  设置项目在后台运行，既不影响用户正常的操作，又降低了打开浏览器对系统内存的占用。

②  采用模块化设计的思想，将相关功能代码封装成函数，通过调用函数实现所有的功能，便于后期代码的维护和修改。

③  设计了将所有文档统一存储在同一个文件夹内的功能，方便不同用户实现不同的需求。

  

#### 2. 开发工具及其依赖 

① 开发语言:python3

② 开发工具:Pycharm、Chrome浏览器

③ 使用到的python内置库和第三方库: selenium ,os,json,time等



#### 3、调试结果

​       该项目是通过控制浏览器来模拟人的操作，从而实现腾讯文档模板的采集，因此速度上远比不上爬虫直接爬取。因暂无VIP账号，故只采集了普通文档。采集的部分文档如下图所示，采集到的文档以模板标题命名，有分类存储和统一存储两种方式供用户选择:
![](http://doc.xjfyt.top/markdown_img/Pasted%20image%2020220701122137.png)